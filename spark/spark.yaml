apiVersion: v1
kind: Pod
metadata:
  name: spark
spec:
  restartPolicy: Never
  containers:
  - name: spark
    image: python:3.13.10-alpine3.22
    imagePullPolicy: IfNotPresent
    command: ["python3","-u","-c"]
    args:
    - |
      #!/usr/bin/env python3
      from os import fchmod
      from time import time,sleep
      SPARK_BASE = "/spark"
      SPARK_YAML = f"{SPARK_BASE}/var/lib/rancher/k3s/server/manifests/spark.yaml"
      SPARK_SKIP = f"{SPARK_YAML}.skip"
      CONFIG_YAML = f"{SPARK_BASE}/etc/rancher/k3s/config.yaml"
      CONFIG_BUF = """
      token: SOME_TOKEN
      agent-token: ANOTHER_TOKEN
      #token: ANOTHER_TOKEN
      secrets-encryption: true
      secrets-encryption-provider: secretbox
      #tls-san: ???
      flannel-backend: "wireguard-native"
      cluster-init: true
      #server: {{ $k3s_url | quote }}
      node-ip: "192.168.56.51"
      flannel-iface: "enp0s8"
      """
      def main():
          print(time(),"begin")
          # https://docs.k3s.io/installation/packaged-components
          # don't let spark.yaml run on k3s(etcd)
          with open(SPARK_SKIP,"w") as fp:
              fchmod(fp.fileno(),0o600)
          with open(CONFIG_YAML,"w") as fp:
              fp.write(CONFIG_BUF.strip() + "\n")
              fchmod(fp.fileno(),0o600)
          print(time(),"end")
          # #chroot /spark systemd-run bash -c 'sleep 1 ; systemctl reboot'
          # # Failed to connect to system scope bus via local transport: No data available
          # chroot "${SPARK_BASE}" systemctl reboot
      if __name__ == "__main__":
          main()
    volumeMounts:
    - mountPath: /spark
      name: vol-host
      readOnly: false
  volumes:
  - name: vol-host
    hostPath:
      path: /
      type: Directory
